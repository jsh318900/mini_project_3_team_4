{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "#  import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:05:38.117925Z",
     "iopub.status.busy": "2023-04-19T04:05:38.116476Z",
     "iopub.status.idle": "2023-04-19T04:05:43.142206Z",
     "shell.execute_reply": "2023-04-19T04:05:43.140918Z",
     "shell.execute_reply.started": "2023-04-19T04:05:38.117775Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:05:43.148727Z",
     "iopub.status.busy": "2023-04-19T04:05:43.147861Z",
     "iopub.status.idle": "2023-04-19T04:05:43.236004Z",
     "shell.execute_reply": "2023-04-19T04:05:43.234594Z",
     "shell.execute_reply.started": "2023-04-19T04:05:43.148686Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('mps')\n",
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T06:25:46.225670Z",
     "iopub.status.busy": "2023-04-19T06:25:46.224898Z",
     "iopub.status.idle": "2023-04-19T06:25:46.231106Z",
     "shell.execute_reply": "2023-04-19T06:25:46.229794Z",
     "shell.execute_reply.started": "2023-04-19T06:25:46.225631Z"
    }
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    # EfficientNet_B3를 사용하기 위해\n",
    "    'IMG_SIZE':300,\n",
    "    # 총 110Epoch 수행\n",
    "    'EPOCHS':30,\n",
    "    'LEARNING_RATE':0.001,\n",
    "    # 8이하를 사용하였을 때, Overfit\n",
    "    'BATCH_SIZE':16,\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:05:48.301869Z",
     "iopub.status.busy": "2023-04-19T04:05:48.300841Z",
     "iopub.status.idle": "2023-04-19T04:05:48.310789Z",
     "shell.execute_reply": "2023-04-19T04:05:48.309589Z",
     "shell.execute_reply.started": "2023-04-19T04:05:48.301831Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T06:26:56.976633Z",
     "iopub.status.busy": "2023-04-18T06:26:56.976257Z",
     "iopub.status.idle": "2023-04-18T06:26:56.981980Z",
     "shell.execute_reply": "2023-04-18T06:26:56.980954Z",
     "shell.execute_reply.started": "2023-04-18T06:26:56.976598Z"
    }
   },
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:05:49.250882Z",
     "iopub.status.busy": "2023-04-19T04:05:49.250472Z",
     "iopub.status.idle": "2023-04-19T04:05:49.337783Z",
     "shell.execute_reply": "2023-04-19T04:05:49.336667Z",
     "shell.execute_reply.started": "2023-04-19T04:05:49.250845Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.loc[(df['id'] == 3896) & (df['artist'] == 'Titian'), ['img_path', 'id', 'artist']] = ['./train/3986.jpg', 3986, 'Alfred Sisley']\n",
    "df.loc[(df['id'] == 3896) & (df['artist'] == 'Edgar Degas'), 'artist'] = 'Titian'\n",
    "df.to_csv('new_train_data.csv', index=False)\n",
    "df = pd.read_csv('new_train_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:05:50.320066Z",
     "iopub.status.busy": "2023-04-19T04:05:50.319322Z",
     "iopub.status.idle": "2023-04-19T04:05:50.336007Z",
     "shell.execute_reply": "2023-04-19T04:05:50.334866Z",
     "shell.execute_reply.started": "2023-04-19T04:05:50.320008Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "df['artist'] = encoder.fit_transform(df['artist'].values)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:05:50.466781Z",
     "iopub.status.busy": "2023-04-19T04:05:50.466187Z",
     "iopub.status.idle": "2023-04-19T04:05:50.475825Z",
     "shell.execute_reply": "2023-04-19T04:05:50.474566Z",
     "shell.execute_reply.started": "2023-04-19T04:05:50.466751Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, val_df, _, _ = train_test_split(df, df['artist'], test_size=0.2,\n",
    "                                          random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:05:51.277055Z",
     "iopub.status.busy": "2023-04-19T04:05:51.276385Z",
     "iopub.status.idle": "2023-04-19T04:05:51.296121Z",
     "shell.execute_reply": "2023-04-19T04:05:51.294983Z",
     "shell.execute_reply.started": "2023-04-19T04:05:51.277018Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sort_values(by=['id'])\n",
    "val_df = val_df.sort_values(by=['id'])\n",
    "\n",
    "display(train_df.head(3))\n",
    "display(val_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:05:52.631732Z",
     "iopub.status.busy": "2023-04-19T04:05:52.630274Z",
     "iopub.status.idle": "2023-04-19T04:05:52.637706Z",
     "shell.execute_reply": "2023-04-19T04:05:52.636538Z",
     "shell.execute_reply.started": "2023-04-19T04:05:52.631682Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(df, infer=False):\n",
    "    if infer:\n",
    "        return df['img_path'].values\n",
    "    return df['img_path'].values, df['artist'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:05:52.888947Z",
     "iopub.status.busy": "2023-04-19T04:05:52.888629Z",
     "iopub.status.idle": "2023-04-19T04:05:52.894960Z",
     "shell.execute_reply": "2023-04-19T04:05:52.893718Z",
     "shell.execute_reply.started": "2023-04-19T04:05:52.888913Z"
    }
   },
   "outputs": [],
   "source": [
    "train_img_paths, train_labels = get_data(train_df) # 4728개\n",
    "val_img_paths, val_labels = get_data(val_df) # 1183개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T06:33:49.811071Z",
     "iopub.status.busy": "2023-04-18T06:33:49.810663Z",
     "iopub.status.idle": "2023-04-18T06:33:49.815581Z",
     "shell.execute_reply": "2023-04-18T06:33:49.814522Z",
     "shell.execute_reply.started": "2023-04-18T06:33:49.811038Z"
    }
   },
   "source": [
    "# 나만의 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:05:54.200747Z",
     "iopub.status.busy": "2023-04-19T04:05:54.199749Z",
     "iopub.status.idle": "2023-04-19T04:05:54.210217Z",
     "shell.execute_reply": "2023-04-19T04:05:54.209124Z",
     "shell.execute_reply.started": "2023-04-19T04:05:54.200687Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, transforms=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        #img_path = img_path.replace('./t', '/t')\n",
    "        #img_path = ('/kaggle/input/artist-data' + img_path)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            label = self.labels[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:06:05.443327Z",
     "iopub.status.busy": "2023-04-19T04:06:05.442970Z",
     "iopub.status.idle": "2023-04-19T04:06:05.455314Z",
     "shell.execute_reply": "2023-04-19T04:06:05.454210Z",
     "shell.execute_reply.started": "2023-04-19T04:06:05.443293Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train 데이터를 위한 증강 및 전처리\n",
    "train_transform = A.Compose([\n",
    "    # test로 주어지는 데이터가 원본사이즈만큼의 1/4 RandomCrop인 점을 감안해 최대한 재현\n",
    "    A.Resize(CFG['IMG_SIZE']*2, CFG['IMG_SIZE']*2), # 300*300\n",
    "    A.RandomCrop(p=1, height=CFG['IMG_SIZE'], width=CFG['IMG_SIZE']),\n",
    "    A.CoarseDropout(max_holes=4, max_height=64, max_width=64, p=0.5),\n",
    "    A.OneOf([\n",
    "         A.MotionBlur(p=1),\n",
    "         A.OpticalDistortion(p=1),\n",
    "         A.GaussNoise(p=1),\n",
    "     ], p=0.3),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),\n",
    "                max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:06:05.443327Z",
     "iopub.status.busy": "2023-04-19T04:06:05.442970Z",
     "iopub.status.idle": "2023-04-19T04:06:05.455314Z",
     "shell.execute_reply": "2023-04-19T04:06:05.454210Z",
     "shell.execute_reply.started": "2023-04-19T04:06:05.443293Z"
    }
   },
   "outputs": [],
   "source": [
    "# Valid 데이터를 위한 증강 및 전처리\n",
    "valid_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE']*2,CFG['IMG_SIZE']*2), # test로 주어지는 데이터 (원본에서 1/4확대)\n",
    "    A.RandomCrop(p=1, height=CFG['IMG_SIZE'], width=CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),\n",
    "                max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Test 데이터를 위한 증강 및 전처리\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),\n",
    "                max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:06:08.504955Z",
     "iopub.status.busy": "2023-04-19T04:06:08.503865Z",
     "iopub.status.idle": "2023-04-19T04:06:08.527540Z",
     "shell.execute_reply": "2023-04-19T04:06:08.526260Z",
     "shell.execute_reply.started": "2023-04-19T04:06:08.504918Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_weights(labels, nclasses):\n",
    "    labels = np.array(labels)\n",
    "    weight_arr = np.zeros_like(labels)\n",
    "\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    for cls in range(nclasses):\n",
    "        weight_arr = np.where(labels == cls, 1/counts[cls], weight_arr)\n",
    "        # 각 클래스의의 인덱스를 산출하여 해당 클래스 개수의 역수를 확률로 할당한다.\n",
    "        # 이를 통해 각 클래스의 전체 가중치를 동일하게 한다.\n",
    "\n",
    "    return weight_arr\n",
    "\n",
    "weights = make_weights(train_labels, len(np.unique(train_labels)))\n",
    "weights = torch.DoubleTensor(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:06:08.899591Z",
     "iopub.status.busy": "2023-04-19T04:06:08.898647Z",
     "iopub.status.idle": "2023-04-19T04:06:08.907790Z",
     "shell.execute_reply": "2023-04-19T04:06:08.906474Z",
     "shell.execute_reply.started": "2023-04-19T04:06:08.899551Z"
    }
   },
   "outputs": [],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:06:09.083571Z",
     "iopub.status.busy": "2023-04-19T04:06:09.082987Z",
     "iopub.status.idle": "2023-04-19T04:06:09.090564Z",
     "shell.execute_reply": "2023-04-19T04:06:09.089443Z",
     "shell.execute_reply.started": "2023-04-19T04:06:09.083531Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_img_paths, train_labels, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], num_workers=0,\n",
    "                           sampler=sampler.WeightedRandomSampler(weights, len(weights)))\n",
    "\n",
    "val_dataset = CustomDataset(val_img_paths, val_labels, valid_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./test.csv')\n",
    "test_df.head(3)\n",
    "\n",
    "test_img_paths = get_data(test_df, infer=True)\n",
    "\n",
    "test_dataset = CustomDataset(test_img_paths, None, test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**원본데이터 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list = np.random.randint(0, len(train_img_paths)-1, 4)\n",
    "\n",
    "figure, axes = plt.subplots(1, 4, figsize=(20, 15))\n",
    "for i, idx in enumerate(rand_list):\n",
    "    img = cv2.imread(train_img_paths[idx])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axes[i].imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**훈련용 데이터 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list = np.random.randint(0, len(train_dataset)-1, 4)\n",
    "\n",
    "figure, axes = plt.subplots(1, 4, figsize=(20, 15))\n",
    "for i, idx in enumerate(rand_list):\n",
    "    img = train_dataset[idx][0].permute(1, 2, 0)\n",
    "    axes[i].imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**검증용 데이터 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list = np.random.randint(0, len(val_dataset)-1, 4)\n",
    "\n",
    "figure, axes = plt.subplots(1, 4, figsize=(20, 15))\n",
    "for i, idx in enumerate(rand_list):\n",
    "    img = val_dataset[idx][0].permute(1, 2, 0)\n",
    "    axes[i].imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**테스트용 데이터 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list = np.random.randint(0, len(test_img_paths)-1, 4)\n",
    "\n",
    "figure, axes = plt.subplots(1, 4, figsize=(20, 15))\n",
    "for i, idx in enumerate(rand_list):\n",
    "    img = cv2.imread(test_img_paths[idx])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axes[i].imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:06:09.670488Z",
     "iopub.status.busy": "2023-04-19T04:06:09.669782Z",
     "iopub.status.idle": "2023-04-19T04:06:09.676985Z",
     "shell.execute_reply": "2023-04-19T04:06:09.675861Z",
     "shell.execute_reply.started": "2023-04-19T04:06:09.670446Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = models.efficientnet_b3(pretrained=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(in_features=1000, out_features=num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:06:09.759630Z",
     "iopub.status.busy": "2023-04-19T04:06:09.758826Z",
     "iopub.status.idle": "2023-04-19T04:06:11.707204Z",
     "shell.execute_reply": "2023-04-19T04:06:11.706092Z",
     "shell.execute_reply.started": "2023-04-19T04:06:09.759591Z"
    }
   },
   "outputs": [],
   "source": [
    "model_Eff = BaseModel(num_classes=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련을 시켜봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:06:11.710047Z",
     "iopub.status.busy": "2023-04-19T04:06:11.709583Z",
     "iopub.status.idle": "2023-04-19T04:06:11.716310Z",
     "shell.execute_reply": "2023-04-19T04:06:11.714692Z",
     "shell.execute_reply.started": "2023-04-19T04:06:11.710008Z"
    }
   },
   "outputs": [],
   "source": [
    "def competition_metric(true, pred):\n",
    "    return f1_score(true, pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:06:11.718864Z",
     "iopub.status.busy": "2023-04-19T04:06:11.718476Z",
     "iopub.status.idle": "2023-04-19T04:06:11.729735Z",
     "shell.execute_reply": "2023-04-19T04:06:11.728595Z",
     "shell.execute_reply.started": "2023-04-19T04:06:11.718803Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(model, criterion, test_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    model_preds = []\n",
    "    true_labels = []\n",
    "    \n",
    "    val_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(iter(test_loader)):\n",
    "            img, label = img.float().to(device), label.to(device)\n",
    "            \n",
    "            model_pred = model(img)\n",
    "            \n",
    "            loss = criterion(model_pred, label)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            model_preds += model_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += label.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    val_f1 = competition_metric(true_labels, model_preds)\n",
    "    return np.mean(val_loss), val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T08:56:01.236143Z",
     "iopub.status.busy": "2023-04-19T08:56:01.235364Z",
     "iopub.status.idle": "2023-04-19T08:56:01.247652Z",
     "shell.execute_reply": "2023-04-19T08:56:01.245926Z",
     "shell.execute_reply.started": "2023-04-19T08:56:01.236101Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, test_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS'] + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        \n",
    "        for img, label in tqdm(iter(train_loader)):\n",
    "            img = img.float().to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            model_pred = model(img)\n",
    "            \n",
    "            loss = criterion(model_pred, label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        tr_loss = np.mean(train_loss)\n",
    "        \n",
    "        val_loss, val_score = validation(model, criterion, test_loader, device)\n",
    "        \n",
    "        print(f'Epoch [{epoch}], Train Loss : [{tr_loss:.5f}] Val Loss : [{val_loss:.5f}] Val F1 Score : [{val_score:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(metrics=val_score)\n",
    "        \n",
    "        if best_score < val_score:\n",
    "            best_model = model\n",
    "            best_score = val_score\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T08:56:01.993557Z",
     "iopub.status.busy": "2023-04-19T08:56:01.993158Z",
     "iopub.status.idle": "2023-04-19T08:56:02.010874Z",
     "shell.execute_reply": "2023-04-19T08:56:02.009689Z",
     "shell.execute_reply.started": "2023-04-19T08:56:01.993523Z"
    }
   },
   "outputs": [],
   "source": [
    "model_Eff.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T08:56:26.854986Z",
     "iopub.status.busy": "2023-04-19T08:56:26.854238Z",
     "iopub.status.idle": "2023-04-19T08:56:26.861937Z",
     "shell.execute_reply": "2023-04-19T08:56:26.860869Z",
     "shell.execute_reply.started": "2023-04-19T08:56:26.854947Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer_Eff = torch.optim.Adam(params=model_Eff.parameters(), lr=1.0000e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T08:56:27.173648Z",
     "iopub.status.busy": "2023-04-19T08:56:27.173318Z",
     "iopub.status.idle": "2023-04-19T08:56:27.180547Z",
     "shell.execute_reply": "2023-04-19T08:56:27.179382Z",
     "shell.execute_reply.started": "2023-04-19T08:56:27.173620Z"
    }
   },
   "outputs": [],
   "source": [
    "scheduler_Eff = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer_Eff,\n",
    "                                                 mode='max', factor=0.1,\n",
    "                                                 patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T08:56:27.502888Z",
     "iopub.status.busy": "2023-04-19T08:56:27.502227Z"
    }
   },
   "outputs": [],
   "source": [
    "infer_model = train(model_Eff, optimizer_Eff, train_loader, val_loader,\n",
    "                    scheduler_Eff, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측해서 제출해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/kaggle/input/artist-data/test.csv')\n",
    "test_df.head(3)\n",
    "\n",
    "test_img_paths = get_data(test_df, infer=True)\n",
    "\n",
    "test_dataset = CustomDataset(test_img_paths, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    model_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img in tqdm(iter(test_loader)):\n",
    "            img = img.float().to(device)\n",
    "            \n",
    "            model_pred = model(img)\n",
    "            model_preds += model_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "    print('Done.')\n",
    "    return model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = encoder.inverse_transform(preds) # LabelEncoder로 변환 된 Label을 다시 화가이름으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('/kaggle/input/artist-data/sample_submission.csv')\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['artist'] = preds\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('/kaggle/working/EFF_B3_300_110Epoch.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(infer_model.state_dict(), 'EFF_B3_300_110Epoch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
